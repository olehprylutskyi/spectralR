---
title: "spectralR: Spectral reflectance visualisations for user-defined areas"
author: "Oleh Prylutskyi, Vladimir Mikryukov, Dariia Borovyk"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{spectralR: Spectral reflectance visualisations for user-defined areas}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The `spectralR` package ([homepage and source code](https://github.com/olehprylutskyi/spectralR)) is aimed to obtain, process, and visualize spectral reflectance data for the user-defined earth surface classes for visual exploring in which wavelengths the classes differ. User-defined classes might represent different habitat or vegetation types, crops, land uses, landscapes, or other territories. Input should be a shapefile with polygons of surface classes (it might be different habitat types, crops, or other things). So far, the single source of spectral data is [Sentinel 2 Level 2A](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2) satellite mission optical bands pixel data, obtained through the [Google Earth Engine](https://earthengine.google.com/) service.

The initial purpose of `spectralR` development was to quickly and visually explore the differences in spectral reflectance patterns for supervised vegetation (and, widely, habitat) mapping. While machine learning classification methods, such as [RandomForest](https://en.wikipedia.org/wiki/Random_forest), typically utilize the full set of available spectral data (satellite bands), we observed that highly similar habitat types (e.g., different types of grasslands, floodplain habitats) might have similar reflectance values during one season and different for another, so time-series reflectance data are also needed. Without the preliminary selection of the most discriminating satellite bands for given habitat types in given conditions, the models became overfitted and required extensive machine resources for calculation.

The [first version](https://github.com/olehprylutskyi/habitat-spectral-reflectance) of our product was based on three code snippets, two written for R (shapefile preparation and visualization of the results) and one for Google Earth Engine for satellite image preparation and spectral data sampling itself. That approach, though, required a bunch of manual operations, and downloading big files on a local machine. So we moved to the recent [rgee](https://r-spatial.github.io/rgee/) R package, which provides a bridge between R and Python API for Google Earth Engine. All the operations with satellite images now run in a cloud, and the obtained pixel data is visualized locally afterward. Therefore, the most resource-hungry functions do not overload your local machine regardless the size of data. However, a stable Internet connection is required for using the API.

The overall workflow is the following:

1.  Load the user's ESRI shapefile containing polygons for user-defined surface classes, as well as the text or numerical field with class names (labels).
2.  Apply `rgee` functionality to retrieve multi-band pixel data for class polygons from the Google Earth Engine service.
3.  Visualize retrieved pixel data locally, using `ggplot2` approach.

Essential requirements:

-   Stable Internet connection (for using API)

-   Installed and correctly pre-configured Python environment (v. 3.5 or above)

-   Active Google Earth Engine account

## Essential preparations

### Install and set up `rgee`

For using `rgee` you should have a Google Earth Engine account. If you don't, first [register](https://earthengine.google.com/new_signup/) using your Google account.

Depending on the operating system you are using and your current Python configuration, it may require the installation of additional R and Python packages for running `rgee`. See the following links for instructions. See also [Quick Start User's Guide](https://www.rdocumentation.org/packages/rgee/versions/1.0.7), [Official documentation](https://r-spatial.github.io/rgee/index.html), and the [source code](https://github.com/r-spatial/rgee) of `rgee` for solving issues that arise during installation and setting up.

We strongly encourage you to follow the official `rgee` installation guide and pay attention to the messages that arrive during installation. Here we guide your for `rgee` installation and first setting up for using `spectralR`
functions.

First, install either stable or development version of the package (all `spectrlR` functions were tested under CRAN version of `rgee`):

```{r, eval = FALSE}
install.packages("rgee") # install regular version from CRAN, more stable
# remotes::install_github("r-spatial/rgee") # to install development version, more recent
```

Load the library:

```{r}
library(rgee)
```

It is necessary just once to complete the installation of the dependencies:

```{r, eval = FALSE}
ee_install()
```

If something went wrong at this step, see `rgee`'s [installation guide](https://r-spatial.github.io/rgee/index.html#installation)

Check non-R dependencies

```{r, eval = FALSE}
ee_check() 
```

`rgee` developers recommend installing the version of the Earth Engine Python API which `rgee` was tested with, using the following command. Although it calls "upgrade", it might actually downgrade your version of `earthengine_api`. You may up(down)grade or not, but in our tests, newer versions of `earthengine_api` worked flawlessly.

```{r, eval = FALSE}
ee_install_upgrade()
```

Initialize the Google Earth Engine API for current session:

```{r, eval = FALSE}
ee_Initialize()
```

At this step, you would be prompted to link your Google Earth Engine account with `rgee`. Follow instructions in the R console, and you will be redirected to a web browser for logging into your Google Earth Engine account to confirm access rights. During this step, you should past an authorization code generated into R console to finalize authentication.

During first initialization the following error message can arise on some systems:

> Error: Exception: gcloud command not found. Please ensure that gcloud is installed.
> More information: https://developers.google.com/earth-engine/guides/python_install

It means that your system lacks Google Cloud Command Line Interface (gcloud), through which graphical authentification using your default web browser is supposed to happen. In this case, please follow [instructions](https://cloud.google.com/sdk/docs/install) to install gcloud CLI manually.

If everything is OK at the last step and you see a message of successful initiation of API with your GEE username in the console, - congratulations, you managed to install and configure `rgee`!

Pay attention that `rgee` uses `earthengine_api` package, which depends on Python. That's why we need to set up a local Python environment for using `rgee`.

Unfortunately, you have to repeat the environment setting and re-authorization each time Python gets updates. For actively updated operating systems, like regular versions of Ubuntu, that's quite annoying. On the other hand, this built-in repairing system protects you from accidentally breaking the `earthengine` Python environment during installation or using any other Python-related tools, which is convenient, at least if you are not very experienced Python user. If you get an error message

> The current Python PATH: /home/user/.virtualenvs/rgee/bin/python does
> not have the Python package "earthengine-api" installed. Are you
> restarted/terminated your R session after install miniconda or run
> ee_install()?

then proceed with the instruction that appeared in R console and will help you to delete your previous configuration and set it up again.

### Installation of the other dependencies

`spectralR` was designed on top of `rgee`, `sf`, and `ggplot2` R packages, which you should install and set up before using `spectralR`. Whilst the other dependencies may be installed automatically during `spectralR` installation process, it is strongly recommended to check also if packages `geojsonio`, `dplyr`, `reshape2`, `tibble`, and `tidyr` are installed and work properly.

### Installation of spectralR

`spectralR` can be installed from **GitHub** sources so far, although we are planning to land it on CRAN soon.

Install the released version from CRAN (recommended):

```{r}
install.packages("spectralR")
```

You can install the development version of `spectralR` from **GitHub** sources:

```{r, eval = FALSE}
library(remotes)
install_github("olehprylutskyi/spectralR")
```

***

We offer two datasets to illustrate the functionality of `spectralR` through the selected use-cases. The first dataset, namely ‘Homilsha Forests’, illustrates the “small data”: small-size area, a small number of polygons (8 polygons) which belong to a few categories (5 land-cover classes). The area belongs to the Homilsha Forests National Park, situated in the Kharkiv region (Eastern Ukraine). The polygons were created manually in the GIS software. Habitat borders and assignments were based on a field survey and adjusted according to the satellite imaginary. The land cover categories correspond to the CORINE classification (level 3) (available via https://land.copernicus.eu/) but some of them have shortened names: cropland = 2.1.1 Non-irrigated arable land; coniferous forest = 3.1.2 Coniferous forest; meadow = 3.2.1 Natural grasslands; reed = 4.1.1 Inland marshes; water = 5.1.2 Water bodies.

The second dataset, ‘Buzkyi Gard’, represents “large data”: a large area with complicated topography, hundreds of polygons, and dozens of classes. End users don't expect to notice large differences in workflow, but under the hood we implemented two different algorithms for either "small" or "large" spatial data, which will be explained later.

## Use case 1. Basic habitat types of 'Homilsha Forests' National Park.

### Environment preparation

```{r, error=FALSE, warning=FALSE, message=FALSE}
# Reset R's brain before the new analysis session started. It will erase all the objects stored in 
# R memory, while keeping loaded libraries.
rm(list = ls())

# Load required packages
library(tidyverse)
library(rgee)
library(sf)
library(geojsonio)
library(reshape2)
library(spectralR)
```

### Upload and process vector data

Function `prepare.vector.data` takes a user's geodata with polygons of different classes of surface (habitats, crops, vegetation, etc.) and retrieves the `simple features` object with all the variables required for interaction with Google Earth Engine. Input data can be either spatial data object ('simple features', 'SpatialPolygonDataFrame', 'spatVector') or user's local file (ESRI Shapefile, KML, and GeoJSON file formats are currently supported). Actually, any spatial polygons which can be converted into `simple features` object and has a variable/field with surface class names can be fed to `prepare.vector.data` function.

One should specify the data/file name (including path for local files) and the name of the variable/field containing class labels. We strongly advise do not use spaces, commas, semicolons, or any other special symbols (#, $, %, !, ?, +, -, @) in label names. Those names are supposed to be used multiple times during further data transformation and visualization, so using ambiguous symbols might cause problems.

The function extracts geometries of all polygons, marks them with custom labels ('label'), and automatically assigns integer class ID ('class') for each entry. The last variable is required because the Google Earth Engine sampler respects only numerical class ID - don't delete any field! Don't panic, the resulting data frame will be marked according to your custom labels, not difficult-to-memorize numbers.

While preparing a local file with polygons using desktop GIS software (e.d., in [QGIS](https://qgis.org/en/site/)), it is highly recommended to follow the recommendation:

* if possible, draw polygons in homogeneous landscapes and avoid class mixture;

* keep geometries simple, if possible. Avoid multipolygons, holes inside polygons, etc.; 

* tiny polygons (same size as satellite imagery resolution or lesser) tend to produce a stronger "edge effect"; 

* few big polygons are easier to process than a lot of small ones; 

* GEE has its own memory limitation, which may result in extended processing time.

```{r}
# Extract polygons from shapefile and prepare `sf` object with proper structure
sf_df <- prepare.vector.data(system.file("extdata/test_shapefile.shp", package = "spectralR"), "veget_type")
```

Explore the resulting spatial object:

```{r}
head(sf_df)
```

User can visually examine polygons with `mapview` package as following:

```{r}
library(mapview)

mapview(sf_df,
        zcol = "label")
```



The example above uses an internal test shapefile. To use your own data, put full shapefile into your working directory and use the following syntax (uncomment the row and change names of the file and variable containing class labels before executing):

```{r, eval = FALSE}
# sf_df <- prepare.vector.data("your-shapefile-within-working-directory-name.shp", "name-of-the-field-with-class-labels")
```

### Obtain pixel values from Sentinel 2A image collection

Function `get.pixel.data` is a heart of `spectralR`. It takes `sf` polygon object obtained at the previous step and retrieves a data frame with brightness values for each pixel intersected with polygons for each optical band of Sentinel-2 sensor, marked according to the label of surface class from the polygons. `get.pixel.data` starts with the conversion of the `sf` object into GEE feature collection. Then it prepares a satellite image for pixel sampling, performs sampling, and finally exports the resulting object back into the (non-spatial) R data frame.

One of the most tricky and issues-causing steps of this procedure is the conversion between GEE feature collection and R `sf` object. `rgee` implements three ways to do so:

* through the JSON translator (`getInfo`, default) 

* using Google Drive (`getInfo_to_asset`) 

* using Google Cloud Storage (`gcs_to_asset`)

The first one is the most straightforward and quick but usable only for small data (less than 15000 entries, or 1.5 MB size local files). The other two require transient storage to store your data between conversions, either Google Drive or  Google Cloud Storage (since Earth Engine is one of the Google web services it seamlessly interacts with both).

In `spectralR`, we use the first two methods, since they don't require paid subscriptions. `get.pixel.data` assesses the size of your `sf` object or a feature collection, then activates either `getInfo` or `getInfo_to_asset` pathway. If your data is considered to be "small", `getInfo` will be used, and you shall notice nothing special. But, if your data is larger than our arbitrary threshold, the method `getInfo_to_asset` will be activated, and you may be prompted to authorize in Google Drive and allow `rgee` to access GDrive files and folders. In such case, please follow instructions in the R console and then in your web browser. You have to do it once when you perform your first 'large' query - your credits will be stored in your local `earthengine` environment. You can also do it in advance, running the following command:

```{r}
ee_Initialize(user = "myemail@gmail.com", drive = TRUE)
```

Don't forget to change "myemail" to your actual Google account username. After that, you will be re-directed to the new tab in web browser to allow Tidyverse API Packages to see, edit, create, and delete all of your Google Drive files. You have to manually put the checkmark in required field, otherwise it won't work.


After authorization and first use, folder *rgee_backup* will be created in your Google Drive storage, where all the intermediate files will be stored. If you run out of storage, `get.pixel.data` won't be able to use your Google Drive as mediating storage, and you will receive an error. Though `get.pixel.data` re-writes objects each time it executes, we strongly recommend cleaning *rgee_backup* folder in your Drive from time to time manually or using the following command from the `rgee` package:

```{r, collapse = TRUE, eval = FALSE}
ee_clean_container(name = "rgee_backup", type = "drive", quiet = FALSE)
```

To use the `get.pixel.data` function, we need to specify some values:

-   polygons of surface classes as an `sf` object, prepared at the
    previous step;

-   starting day for Sentinel image collection in "YYYY-MM-DD" format.
    See Note 1 below;

-   final day for Sentinel image collection, in "YYYY-MM-DD" format;

-   cloud threshold (maximum percent of cloud-covered pixels per image)
    by which individual satellite imageries will be filtered;

-   a scale of resulting satellite images in meters (pixel size). 
    See Note 2 below;

The resulting pixel data will be saved within a working directory and can be loaded during the following sessions.

**Note 1**. Particular satellite imagery is usually not ready for instant sampling -- it contains clouds, cloud shadows, aerosols, and might cover not all the territory of your interest. Another issue is that each particular pixel slightly differs in reflectance between images taken on different days due to differences in atmospheric conditions and angle of sunlight at the moments images were taken. The Google Earth Engine has its build-in algorithms for image pre-processing, atmospheric corrections and mosaicing, which allows one to obtain a ready-to-use, rectified image. The approach which is used in `spectralR` is to find a median value for each pixel between several images within each of 10 optical bands, thereby making a composite image. To define a set of imageries between which we are going to calculate the median, we should set a timespan of image collection. Sentinel-2 apparatus takes a picture once every five days, so if you set up a month-long timesnap, you can expect that each pixel value will be calculated based on 5 to 6 values (remember, some images might appear unsatisfactory cloudy).

**Note 2**. The finest resolution for Sentinel data is 10 m while using a higher *scale_value* decreases the required computational resources and size of the resulting data frame. Although sampling satellite data is performed in a cloud, there are some limitations for geocalculations placed by GEE itself. If you are about to sample large areas, consider setting a higher 'scale' value (e.g., 100, 1000). Read more in GEE [best practices](https://developers.google.com/earth-engine/guides/best_practices).

```{r, collapse = TRUE, eval = FALSE}
# Get pixel data
reflectance = get.pixel.data(sf_data = sf_df,
                             startday = "2019-05-15",
                             endday = "2019-06-30",
                             cloud_threshold = 10,
                             scale_value = 100)

# You can save pixel data for further sessions
save(reflectance, file = "reflectance_test_data.RData")
```

```{r, include = FALSE}
load(file = "../inst/testdata/reflectance_test_data.RData")
```

Here we choose the 100 m scale (pixel size for resulting imagery is 100x100 m), which resulted in a sampling dataset of 2060 rows. Finer pixel size would result in a larger sampling dataset, which would require using moderating storage (see use case 2).

```{r, echo = FALSE, eval = FALSE}
load(file = "./reflectance_test_data") # restore previously saved pixel data
```

Let's have a look at the resulting data:

```{r}
head(reflectance)
```

We have a data frame with the number of rows equal to the number of sampled "pixels" of satellite image and 10 variables with reflectance values for each optical band of Sentinel 2. Each sampled pixel has a label of a surface class of the user's polygon it intersected.

Note: `spectralR` receives true reflectance values (between 0 and 1), transforming **GEE**'s values (multiplied by 10000 for calculation convenience).

### Visualize results

First of all, one should explore the quality and comprehensiveness of obtained pixel data.

```{r}
# load(file = "./reflectance_test_data") # restore previously saved pixel data

summary(factor(reflectance$label)) # how many pixels in each class? 
```

For reliable results, keeping the similar size of each surface class is recommended. Classes represented by a few sampled pixels better to be excluded from further analysis.

Visual overview of pixel data

```{r, fig.align='center', fig.width=7, fig.height=5}
# Number of spectral values for different classes
ggplot(reflectance, aes(x=label))+
  geom_bar()+
  labs(x = 'Classes of surface', y = 'Number of pixels',
       title = "Total pixel data for different classes of surface",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

Function `stat.summary.plot` make a plot with a statistical summary of reflectance values (mean, mean - standard deviation, mean + standard deviation) for defined classes of the surface. It gives reflectance data as an input, and returns a `ggplot2` object with minimal visual aesthetics. Default aesthetics are line with a statistical summary for each satellite band ([geom_line](https://ggplot2.tidyverse.org/reference/geom_linerange.html) + [geom_pointrange](https://ggplot2.tidyverse.org/reference/geom_path.html)).

Wavelength values (nm) are acquired from the mean known value for each optical band of the [Sentinel 2](https://en.wikipedia.org/wiki/Sentinel-2) sensor.

```{r, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p2 <- stat.summary.plot(reflectance)

# Default plot
p2
```

Since the output of `spectral.curves.plot` is a most simple as possible `ggplot` object, we can apply any tools provided by `ggplot2` package to make it more appealing.

```{r, , fig.align='center', fig.width=7, fig.height=5}
# Customized plot
p2 + 
  labs(x = 'Sentinel-2 bands', y = 'Reflectance',
       colour = "Surface classes",
       title = "Reflectance for different surface classes",
       caption='Data: Sentinel-2 Level-2A\nmean ± standard deviation')+
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

Save the plot as a \*.png file

```{r}
ggsave("Statsummary_usecase1.png", width = 16, height = 12, unit = "cm", dpi = 300)
```


Function `spectral.reflectance.curve` transform the data and plot smoother curves for each surface class, using `ggplot2`'s `geom_smooth()` aesthetics. For large (thousands of rows) data (and we need large data for reliable conclusions!), `ggplot2` uses the *GAM* method for drawing smoothers.

Depending on the data size, the processing may take some time.

```{r, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p1 <- spectral.curves.plot(reflectance)

# Default plot
p1
```

Add a touch of customization.

```{r, fig.align='center', fig.width=7, fig.height=5}
# Customized plot
p1+
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Surface classes",
       fill = "Surface classes",
       title = "Spectral reflectance curves for different surface classes",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

You can save the plot as a \*.png (or other standard graphical formats) file using `ggsave`, `png()`, `svg()` functions or similar.

```{r}
ggsave("Spectral_curves_usecase1.png", width = 16, height = 12, unit = "cm", dpi = 300)
```

Function `violin.plot` helps to visualize a reflectance as violin plots for each surface class per satellite bands. It gets reflectance data as input and returns *ggplot2* object with basic visual aesthetics. The default aesthetics is [geom_violin](https://ggplot2.tidyverse.org/reference/geom_violin.html).

```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p3 <- violin.plot(reflectance)

# Customized plot
p3 + 
  labs(x='Surface class',y='Reflectance',
       fill="Surface classes",
       title = "Reflectance for different surface classes",
       caption='Data: Sentinel-2 Level-2A')+
  theme_minimal()

# Save the plot as a *.png file
ggsave("Violins_usecase1.png", width=22, height=16, unit="cm", dpi=300)
```

## Use case 2. Habitats of Buzkyi Gard National Park, Mykolaiv region, Ukraine.

[**Buzkyi Gard National Park**](https://en.wikipedia.org/wiki/Buzk%27s_Gard_National_Nature_Park) is located in Southern Bug valley (south-western Ukraine, 31.08325,47.90720). The National Park is characterized by unique steppe zone landscapes with diverse vegetation and flora (Shyriaieva et al., 2022). Natural habitats with high conservation value, i.e., a wide range of dry grasslands, rocky outcrops, and steppe forests, are concentrated in river valleys and surrounded by croplands. The habitat types were defined using precise vegetation data (phytosociological relevés with GPS location) and field mapping data for the artificial habitats. Then, the new revised version of [**EUNIS expert system**](https://onlinelibrary.wiley.com/doi/10.1111/avsc.12519), [**version 2021-06-01**](https://zenodo.org/record/4812736) with additions from the old [**EUNIS 2007**](https://www.eea.europa.eu/data-and-maps/data/eunis-habitat-classification-1/habitats/eunis-habitats-complete-with-descriptions.xls) for non-revised habitat groups and the [**National Habitat Catalogue of Ukraine**](https://www.researchgate.net/publication/331935396_NATIONAL_HABITAT_CATALOGUE_OF_UKRAINE) were used for the classification. As a result, the dataset contains 380 hand-drawn polygons of 26 different EUNIS habitat types. 

Environment preparation

```{r, error=FALSE, warning=FALSE, message=FALSE}
# Reset R's brain before the new analysis session started. It will erase all the objects stored in 
# R memory while keeping loaded libraries.
rm(list = ls())

# Load required packages
library(tidyverse)
library(rgee)
library(sf)
library(geojsonio)
library(reshape2)
library(spectralR)
```

Upload and process vector data.

```{r}
# Extract polygons from shapefile and prepare sf object with proper structure
sf_df <- prepare.vector.data(system.file("extdata/SouthernBuh-habitats_shapefile.shp", package = "spectralR"), "eunis_2020")
```

Explore the resulting spatial object:

```{r}
head(sf_df)
```

Get reflectance values

```{r, eval = FALSE}
reflectance = get.pixel.data(sf_data = sf_df,
                             startday = "2019-05-15",
                             endday = "2019-06-30",
                             cloud_threshold = 10,
                             scale_value = 10)

# save pixel data for further sessions
save(reflectance, file = "reflectance_BG_data") 
```

```{r, include = FALSE}
load(file = "../inst/testdata/reflectance_BG_data.RData")
```

Some habitat types of the Southern Buh River Valley cover small area (especially rocky outcrops, grasslands, etc.). Therefore, many polygons are relatively small -- up to 1 ha -- and have an irregular shape.  We recommend decreasing scale values (pixel size) in such cases, approaching the minimum value (10 m). On the other hand, that will require more computational power and processing time.

Quantitative overview of pixel data

```{r}
summary(factor(reflectance$label)) # how many pixels in each class?
```

As we explained above, `spectralR` uses your Google Drive as intermittent storage between **R** and **GEE** to dealing with "big data". Please take care of having enough storage in the Drive and purge *rgee_backup* directory manually from time to time.

Spectral reflectance curves for different habitat types

```{r, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p1 <- spectral.curves.plot(reflectance)

# Plotting
p1 +
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Habitat types",
       fill = "Habitat types",
       title = "Spectral reflectance curves for different habitat types\nSouthern Bug National park, Ukraine",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

The plot above, unlike the one from use-case 1, looks messy and hard to read, because of a large number of surface classes (habitat types). To make the resulting plot easier to comprehend, both functions `spectral.curves.plot` and `stat.summary.plot` have optional argument *target_classes*, which takes as an input the list of the classes of surface which should be highlighted, while others will be turned in gray, as a background. Defaults value is NULL - all the classes would be colourized, as above. Let's give it a try.

```{r, fig.align='center', fig.width=7, fig.height=5}
p1_1 <- spectral.curves.plot(
  data = reflectance, 
  target_classes = list("C2.2", "C2.3", "J5")
  )

# Plotting
p1_1 +
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Habitat types",
       fill = "Habitat types",
       title = "Spectral reflectance curves for different habitat types\nSouthern Bug National park, Ukraine",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

Not to mention, that the user is always able to filter the input data to obtain what they want.

Suppose we need only grasslands in our reflectance plot (habitats which code started from R) and want to highlight the differences/similarities in spectral reflectance of Continental dry grasslands (true steppe, type R1B).

```{r, fig.align='center', fig.width=7, fig.height=5}
# Filter reflectance data
grasslands <- reflectance %>%
  filter(label %in% c("R12", "R1A", "R1B", "R21", "R36"))

# Construct a ggplot object with basic aestetics 
p1_2 <- spectral.curves.plot(
  data = grasslands, 
  target_classes = list("R1B")
  )

# Plotting
p1_2 +
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Habitat types",
       fill = "Habitat types",
       title = "Spectral reflectance curves for different types of\ngrassland habitats, Southern Bug National park, Ukraine",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```


Statistical summary for each habitat type

```{r, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p2 <- stat.summary.plot(reflectance)

# Plotting
p2 + 
  labs(x = 'Sentinel-2 bands', y = 'Reflectance',
       colour = "Habitat types",
       title = "Reflectance for different habitat types\nSouthern Bug National park, Ukraine",
       caption='Data: Sentinel-2 Level-2A\nmean ± standard deviation')+
  theme_minimal()
```

Same way, create a plot that highlighted only tall-helophyte beds (type Q51), compared to two common other floodplain habitat types (R21 Mesic lowland pasture, T11 Riparian forest).

```{r, fig.align='center', fig.width=7, fig.height=5}
# Filter reflectance data
floodplain <- reflectance %>%
  filter(label %in% c("Q51", "R21", "T11"))

# Create basic ggplot object
p2_1 <- stat.summary.plot(
  data = floodplain, 
  target_classes = list("Q51")
)

# Plotting
p2_1 + 
  labs(x = 'Sentinel-2 bands', y = 'Reflectance',
       colour = "Habitat types",
       title = "Reflectance of tall-helophyte beds,\nSouthern Bug National park, Ukraine",
       caption='Data: Sentinel-2 Level-2A\nmean ± standard deviation')+
  theme_minimal()
```

Create a violin plots for given habitat types

```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p3 <- violin.plot(reflectance)

# Plotting
p3 + 
  labs(x = "Habitat type", y = "Reflectance",
       fill = "Habitat types",
       title = "Reflectance for different habitat types\nSouthern Bug National park, Ukraine",
       caption ='Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

You also can save and/or transform resulting ggplot objects as you wish, using `ggplot2` and `tidyverse` syntax.

------------------------------------------------------------------------

If you have any feedback, please let us know via [GitHub Issues](https://github.com/olehprylutskyi/spectralR/issues) or [e-mail](mailto:oleh.prylutskyi@gmail.com).

`spectralR` development team. GPL-3.0 License. Document updated 2023-05-28
